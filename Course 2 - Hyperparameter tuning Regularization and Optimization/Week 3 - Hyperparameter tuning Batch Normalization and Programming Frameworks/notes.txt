--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| 0. Hyperparameter Tuning
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

	Common hyperparameters and importance tier (just general rule of thumb)
	-	Tier 1:	Alpha
	-	Tier 2:	Beta 							(~0.9)						(For momentum)
					Hidden units
					Mini-batch size
	-	Tier 3:	Number of layers
					Learning rate decay
	-	Tier 4:	Beta1, Beta2, Epsilon 	(~0.9, ~0.99, ~10^-8)	(For Adams - rarely tuned)
					
					
	Method for finding hyperparameters
	-	For two hyperparameters - use a grid and systematically find the best combination
	-	There is no good systematic way of finding hyperparameters when there are more than two
	-	Instead use randomized values and test
	
	
	Course to fine search process
	- 	Find a rough estimate of good starting hyperparameters (either by randomizing or grid)
	-	Narrow the scale on the search around this estimate and find new hyperparameters there
	-	Can be done several times
	
	Finding a good scale
	-	Some hyperparameters makes sense to just find the min and max values and randomize inbetween
	-	Example:	Number of layers or hidden units
	-	Others work better with a logaritmic scale	
	-	Example:	Randomizing alpha between 0.0001 - 1 will give few results where the number of decimals
					are significant. Therefore randomizing on a logaritmic scale makes more sense.
					r = -4*np.random.rand()	=>	alpha = 10**(r)
					
	Hyperparameter for exponentially weighted averages
	-	Instead if sampling beta 0.9 ... 0.999 we rather sample 1 - beta 0.1 ... 0.001 and use logaritmic scale
	-	Example: 0.1 ... 0.001 = 10**-1 ... 10**-3, r => [-3, 1]		1 -beta = 10**r		beta = 1 - 10**r
		r = np.random.rand()
		beta = 1-10**(- r + 1)
	
	Tuning in practice
	-	Hyperparameters are not forever, data or algorithms change, so every once in a while it is good to reevaluate the choice of hyperparameters
	
	-	Babysitting one model 	- 	If you have big models and limited computation it is common to train one 
											model and keep track as it progresses to make adjustments
											
	-	Parallel models			- 	If you have alot of computation power then it is good training many models 
											in parallel and compare them
					

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| 1. Batch Normalization
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

	Normalization of activation functions in a network
	-	Similarly as to why it is good to normalize inputs it is also good to normalize activation functions
	-	Formula:	mu 		= (1/m)*sum(z(i)) 								where i -> m
					z(i)norm = (z(i) - mu)/sqrt(theta**2 + epsilon)		epsilon is to avoid dividing by zero
					~z(i) 	= gamma*z(i)norm + beta
	-	Beta, Gamma and Epsilon are not the same as in Momentum/Adams
	-	Dimensions: (n[l], l), (n[l], l), (n[l], l) respectively 
					
					
	Fitting Batch Norm into a NN
	-	Calculate z(i) like always
	-	Use it z(i) to calculate ~z(i)
	-	Use ~z(i) to calculate a(i)

	Implementation of gradient descent with Batch Norm
	-	for t = 1..num_mini_batches
			Compute forward prop on X{t}
				In each hidden layer use BN to replace z[l] with ~z[l]
			Use backprop to compute dW[l], dBeta[l], dGamma[l]	(db[l] is eliminated with BN since the mean is zero)
			Update parameters:	W[l] 		= W[l] - alpha*dW[l]
										Beta[l]	= Beta[l] - alpha*dBeta[l]
										Gamma[l]	= Gamma[l] - alpha*dBeta[l]
										
	Batch Norm intuition
	-	As mentioned, BN helps by normalizing in the same way as with inputs, but it also has other benefits
	-	Makes weights later in the network less affected by weights early in the neural network by avoiding accumulation due to "covariate shift"
	-	Batch norm also has a regularzation effect by adding noise in the z(i) -> ~z(i) conversion
	
	
	Batch Norm at test time
	-	During training mu and sigma square on each batch
				

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| 2. Multi-class classification
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


	Softmax Regression
	-	Can recognize several classes
	-	Always has an "other" class
	-	Notation - C = number of classes	C = n[L]
	-	The last layer in the network is the Softmax Layer and corresponds the the number of classes (other included)
	-	C = 2 gives logistic regression
	-	Softmax is contrasting to hardmax where softmax gives a probability vector with values 0 - 1
	-	Hardmax instead gives a probability vector with values either 0 or 1 (only one can be 1)

	Activation function in softmax layer
	-	t = e**(z[l])
	-	a[l] = (e**(z[l]))/sum(t(j))	where sum j -> (C - 1)
	
	Example of activation function
					| 5 |					| e**5 |																	| (e**5)/176.3 |
	-	z[l] = 	| 2 |	 ->	t : 	| e**2 |	* sum(t(j)) =	176.3	 ->	a[l] : t/(176.3) = 	| (e**2)/176.3 |
					|-1 |					| e**-1|																	|(e**-1)/176.3 |			
					| 3 |					| e**3 |																	| (e**3)/176.3 |
					
	Cost/loss function for softmax
	-	L(y_hat,y) = -sum(y(j)*log(y_hat(j)))
	-	J = (1/m)*sum(L(y_hat,y))
	
	Backprop for softmax
	-	dJ/dz[l] = y_hat - y

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| 3. Introduction to programming frameworks
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

	TensorFlow
	-	Builds a computational graph using your forward prop and then automatically performs the backprop
	-	The tf.sessions is where the built graph is run
	-	Placeholders variables (your data) that are provided in the feed_dict used in sess.run(train, feed_dict = {x:value})
	
	Step by step
	-	Create Tensors (variables) that are not yet executed/evaluated.
	-	Write operations between those Tensors.
	-	Initialize your Tensors.
	-	Create a Session.
	-	Run the Session. This will run the operations you'd written above
